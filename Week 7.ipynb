{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e314254",
   "metadata": {},
   "source": [
    "# Diabetes Dataset Classification\n",
    "This notebook performs classification on the diabetes dataset using scikit-learn. It includes the following steps:\n",
    "- Load the diabetes dataset\n",
    "- Train a Decision Tree classifier\n",
    "- Train a Random Forest classifier and compare its performance with the Decision Tree\n",
    "- Apply Bagging to improve the Random Forest model\n",
    "- Perform a significance test on all three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cdf25b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import f_oneway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5bf4631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the diabetes dataset\n",
    "data = load_diabetes()\n",
    "X = data.data\n",
    "y = data.target\n",
    "# Convert target to binary classification (e.g., above or below median)\n",
    "y = (y > np.median(y)).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "733dbe81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.67\n"
     ]
    }
   ],
   "source": [
    "# Train a Decision Tree classifier\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "print(f'Decision Tree Accuracy: {dt_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a964c6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.72\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest classifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8d59bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Khor Kean Teng\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Random Forest Accuracy: 0.73\n"
     ]
    }
   ],
   "source": [
    "# Apply Bagging to improve the Random Forest model\n",
    "bagging_model = BaggingClassifier(base_estimator=RandomForestClassifier(random_state=42), random_state=42)\n",
    "bagging_model.fit(X_train, y_train)\n",
    "bagging_predictions = bagging_model.predict(X_test)\n",
    "bagging_accuracy = accuracy_score(y_test, bagging_predictions)\n",
    "print(f'Bagging Random Forest Accuracy: {bagging_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07057c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significance Test between Decision Tree and Random Forest:\n",
      "T-statistic: 0.0, P-value: 1.0\n",
      "Significance Test between Decision Tree and Bagging:\n",
      "T-statistic: -1.1491423807712053, P-value: 0.25361103536435814\n",
      "Significance Test between Random Forest and Decision Tree:\n",
      "T-statistic: 0.0, P-value: 1.0\n",
      "Significance Test between Random Forest and Bagging:\n",
      "T-statistic: -2.288688541085317, P-value: 0.024492231010549658\n",
      "Significance Test between Bagging and Decision Tree:\n",
      "T-statistic: 1.1491423807712053, P-value: 0.25361103536435814\n",
      "Significance Test between Bagging and Random Forest:\n",
      "T-statistic: 2.288688541085317, P-value: 0.024492231010549658\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# Perform Significance Test on All Models\n",
    "# Collect predictions\n",
    "predictions = {\n",
    "    \"Decision Tree\": dt_predictions,\n",
    "    \"Random Forest\": rf_predictions,\n",
    "    \"Bagging\": bagging_predictions\n",
    "}\n",
    "\n",
    "# Perform paired t-test\n",
    "for model1, pred1 in predictions.items():\n",
    "    for model2, pred2 in predictions.items():\n",
    "        if model1 != model2:\n",
    "            t_stat, p_value = ttest_rel(pred1, pred2)\n",
    "            print(f\"Significance Test between {model1} and {model2}:\\nT-statistic: {t_stat}, P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023e7a26",
   "metadata": {},
   "source": [
    "Okay, let's break down the output of the paired t-tests comparing the predictions of the three models:\n",
    "\n",
    "1.  **What the Test Does:** The paired t-test compares the predictions of two models on the *same* set of test instances. It checks if the difference in predictions between the two models is statistically significant or likely due to random chance. The null hypothesis is that there is no difference between the models' predictions.\n",
    "    *   **T-statistic:** Measures the size of the difference relative to the variation in the sample data. A larger absolute value indicates a larger difference.\n",
    "    *   **P-value:** Represents the probability of observing the data (or something more extreme) if the null hypothesis (no difference) were true. A small p-value (typically < 0.05) suggests that you can reject the null hypothesis and conclude there is a statistically significant difference between the models' predictions.\n",
    "\n",
    "2.  **Analysis of Results:**\n",
    "\n",
    "    *   **Decision Tree vs. Random Forest (and vice-versa):**\n",
    "        *   T-statistic: 0.0\n",
    "        *   P-value: 1.0\n",
    "        *   **Explanation:** The t-statistic is 0 and the p-value is 1.0. This indicates that there is *no statistically significant difference* between the predictions made by the Decision Tree and the standard Random Forest model on this specific test set. Their predictions might even be identical for this run.\n",
    "\n",
    "    *   **Decision Tree vs. Bagging (and vice-versa):**\n",
    "        *   T-statistic: +/- 1.149\n",
    "        *   P-value: 0.254\n",
    "        *   **Explanation:** The p-value (0.254) is much greater than the common significance threshold of 0.05. Therefore, there is *no statistically significant difference* between the predictions of the Decision Tree and the Bagging Random Forest model. While their predictions might differ slightly, the difference isn't large enough to be considered statistically meaningful based on this test.\n",
    "\n",
    "    *   **Random Forest vs. Bagging (and vice-versa):**\n",
    "        *   T-statistic: +/- 2.289\n",
    "        *   P-value: 0.024\n",
    "        *   **Explanation:** The p-value (0.024) is less than 0.05. This indicates that there *is a statistically significant difference* between the predictions made by the standard Random Forest model and the Bagging Random Forest model.\n",
    "\n",
    "3.  **Important Findings:**\n",
    "\n",
    "    *   The most crucial finding is the **statistically significant difference between the standard Random Forest and the Bagging Random Forest** (p = 0.024). This suggests that applying Bagging on top of the Random Forest led to a demonstrably different set of predictions compared to the standard Random Forest alone.\n",
    "    *   Interestingly, neither the standard Random Forest nor the Bagging Random Forest showed a statistically significant difference when compared to the simpler Decision Tree model on this dataset and split. This might imply that for this specific problem setup, the ensemble methods didn't provide a significantly *different* predictive behavior compared to the single tree, even though the Bagging approach did alter the Random Forest's predictions significantly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
